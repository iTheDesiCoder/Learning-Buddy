# Chapter 7: Performance Optimization in Pandas

In this module, we will learn techniques to **optimize performance and memory usage** in Pandas.  
This is very important in the **financial industry**, where datasets can be very large.

We will use **Customer.csv** and **Order.csv** for examples.

---

## 1. Checking Memory Usage

```python
import pandas as pd

customers = pd.read_csv("Customer.csv")
print(customers.memory_usage(deep=True))

orders = pd.read_csv("Order.csv")
print(orders.memory_usage(deep=True))
```

This shows how much memory each column consumes.

---

## 2. Converting Data Types

Strings like `State` and `SecurityType` are repeated many times.  
Convert them to **category type** to save memory.

```python
customers["State"] = customers["State"].astype("category")
orders["SecurityType"] = orders["SecurityType"].astype("category")

print(customers.dtypes)
print(customers.memory_usage(deep=True))
```

---

## 3. Using Efficient Numeric Types

By default, Pandas may use 64-bit integers.  
If values are small, downcast them to smaller types.

```python
orders["Qty"] = pd.to_numeric(orders["Qty"], downcast="integer")
orders["Price"] = pd.to_numeric(orders["Price"], downcast="float")

print(orders.dtypes)
```

---

## 4. Chunked Reading for Large Files

If a file is too large to load at once, read it in **chunks**.

```python
chunk_iter = pd.read_csv("Order.csv", chunksize=20)

for chunk in chunk_iter:
    print(chunk.head(2))
```

üëâ Each chunk is a DataFrame. You can process and aggregate results incrementally.

---

## 5. Comparing Pandas vs Dask

Dask automatically handles partitioning and parallelism.  
For very large datasets, prefer Dask.

```python
import dask.dataframe as dd

df_dask = dd.read_csv("Order.csv")
print(df_dask["Price"].mean().compute())
```

---

## 6. Vectorization vs Loops

Avoid Python loops over rows. Use vectorized operations.

```python
# Slow: Python loop
orders["TotalLoop"] = [q*p for q,p in zip(orders["Qty"], orders["Price"])]

# Fast: Vectorized
orders["TotalVectorized"] = orders["Qty"] * orders["Price"]
```

---

# üìù Practice Exercises

1. Check memory usage of Customer and Order DataFrames.  
2. Convert `SecurityType` and `State` to categorical and measure memory savings.  
3. Downcast `Qty` and `Price` to smaller numeric types.  
4. Read Order.csv in chunks of 15 rows and compute the average `Price`.  
5. Compare computing mean `Price` in Pandas vs Dask.  
6. Create `TotalValue` using both loop method and vectorized method, compare performance.  
